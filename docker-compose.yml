version: "3.4"

services:
  localstack:
    image: localstack/localstack:latest
    environment:
      - SERVICES=s3
      - PORT_WEB_UI=8081
      - DEFAULT_REGION=eu-west-2
      - AWS_ACCESS_KEY_ID=foo
      - AWS_SECRET_ACCESS_KEY=bar
    ports:
      - "8081:8081"

  awscli:
    build:
      context: .
      dockerfile: Dockerfile.awscli
    working_dir: /src/app
    volumes:
      - ./scripts/create-s3-buckets.sh:/src/app/create-s3-buckets.sh
      - ./tests/assets/elife-666-vor-r1.zip:/src/app/elife-666-vor-r1.zip
      - ./tests/assets/elife-666-vor-r2.zip:/src/app/elife-666-vor-r2.zip
    command: ./create-s3-buckets.sh
    depends_on:
      - localstack
    environment:
      WAIT_HOSTS: localstack:4572, localstack:4563
      LOCALSTACK_HOST: localstack

  db:
    image: postgres:11.2
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: example
      POSTGRES_DB: airflow-db
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 30s
      retries: 3

  app:
    build:
      target: base
      context: .
    image: libero/jats-ingester:${IMAGE_TAG:-master}
    command: sh

  airflow_initdb:
    &airflow
    build:
      target: dev
      context: .
    command: upgradedb
    depends_on:
      - db
    environment:
      WAIT_HOSTS: db:5432
    volumes:
      - ./dags:/airflow/dags
      - ./config/aws_dev_config:/airflow/.aws/config
      - ./config/airflow.dev.cfg:/airflow/airflow.cfg
    depends_on:
      - app

  airflow_webserver:
    <<: *airflow
    command: webserver -p 8080
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD-SHELL", "python ./scripts/airflow_healthcheck.py"]
      interval: 30s
      timeout: 30s
      retries: 3

  airflow_scheduler:
    <<: *airflow
    command: scheduler

  airflow_worker:
    <<: *airflow
    command: worker
